{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for  generating data for images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# using adam as optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#cnn2d and max pooling to decrese time taken and for optimization purposes\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "#dropout to avoid overfitting\n",
    "from keras.layers import Dense, Dropout\n",
    "#normalizes the contributions to a layer for every mini-batch\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "# to exit the model if the accuracy isnt incresing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# model we are going to use\n",
    "from keras.models import Sequential\n",
    "# to list images\n",
    "import os\n",
    "# to better work with arrays\n",
    "import numpy as np\n",
    "# to use tensors and other tensorflow variables\n",
    "import tensorflow as tf\n",
    "# to get imgae data for test\n",
    "from PIL import Image\n",
    "# to see progress \n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# rescaling the pixels and splitting them into train test\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255, validation_split=0.2)\n",
    "\n",
    "# making images to generators preapering them to train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    \"imgs/train\",\n",
    "                                                    target_size = (200, 100),\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    batch_size = 64,\n",
    "                                                    subset='training'\n",
    "                                                    )\n",
    "                                                    \n",
    "# making images to generators preapering them to train      \n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                                                    \"imgs/train\",\n",
    "                                                    target_size=(200, 100),\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 198, 98, 32)       896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 198, 98, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 198, 98, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 198, 98, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 99, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 99, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 99, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 99, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 99, 49, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 99, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 50, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 50, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 50, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 50, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 50, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               21299712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 21,657,514\n",
      "Trainable params: 21,655,594\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## CNN 1\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(200, 100, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## CNN 2\n",
    "model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## CNN 3\n",
    "model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "281/281 [==============================] - 1660s 6s/step - loss: 1.2108 - acc: 0.6133 - val_loss: 4.2658 - val_acc: 0.4628\n",
      "Epoch 2/5\n",
      "281/281 [==============================] - 1662s 6s/step - loss: 0.4660 - acc: 0.8520 - val_loss: 0.6312 - val_acc: 0.8395\n",
      "Epoch 3/5\n",
      "281/281 [==============================] - 1655s 6s/step - loss: 0.4102 - acc: 0.8792 - val_loss: 0.3458 - val_acc: 0.9324\n",
      "Epoch 4/5\n",
      "281/281 [==============================] - 1658s 6s/step - loss: 0.2730 - acc: 0.9208 - val_loss: 0.1628 - val_acc: 0.9721\n",
      "Epoch 5/5\n",
      "281/281 [==============================] - 1650s 6s/step - loss: 0.1839 - acc: 0.9484 - val_loss: 2.5986 - val_acc: 0.9462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244e5e03850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop early\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "# model traning\n",
    "model.fit(train_generator,epochs = 5,batch_size =64,validation_data=validation_generator,callbacks = [es],verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# model.save(\"best_model_1.h5\")\n",
    "\n",
    "# load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to generate text according to predicted number\n",
    "class_dict = {0 : \"safe driving\",\n",
    "              1 : \"texting - right\",\n",
    "              2 : \"talking on the phone - right\",\n",
    "              3 : \"texting - left\",\n",
    "              4 : \"talking on the phone - left\",\n",
    "              5 : \"operating the radio\",\n",
    "              6 : \"drinking\",\n",
    "              7 : \"reaching behind\",\n",
    "              8 : \"hair and makeup\",\n",
    "              9 : \"talking to passenger\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to convert image to array using pil\n",
    "def image_to_array(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img = img.resize((200, 100))\n",
    "    data = np.asarray(img,dtype='float32')\n",
    "    data= tf.reshape(data, (-1,200, 100, 3))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [20:00<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#store predictions\n",
    "predicted={}\n",
    "\n",
    "# loop over images and predict its class\n",
    "for i in tqdm(range(10000)):\n",
    "    image=os.listdir(\"imgs/test\")[i]\n",
    "    img_path=f\"imgs/test/{image}\"\n",
    "    img=image_to_array(img_path)\n",
    "    y_pred=model.predict(img)\n",
    "    y_pred=class_dict[np.argmax(y_pred)]\n",
    "    predicted[image]=y_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aba41ee7bc3237da56552c480575885759b5b151384e1586af5593fd87fa3205"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
